{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Young931127/ai-dream-analyzer/blob/main/final_project_analyzer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9STlWRb3JaY",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**環境設置**\n",
        "* **langchain & faiss**: 用於RAG與向量資料庫\n",
        "* **groq & huggingface_hub**: 用於呼叫LLM與繪圖API\n",
        "* **diffusers**: 用於生成圖片"
      ],
      "metadata": {
        "id": "RqWWZKdcuE4I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5q3_zm7L3OHb",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain langchain-community faiss-cpu sentence-transformers transformers huggingface_hub groq diffusers accelerate safetensors invisible_watermark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rB4vH15h5nY7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import torch\n",
        "import gradio as gr\n",
        "from groq import Groq\n",
        "from diffusers import AutoPipelineForText2Image\n",
        "from huggingface_hub import login ,InferenceClient\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**身分驗證與API KEY設定**\n",
        "1.  從colab secret讀取API KEY\n",
        "2.  若讀取失敗讓使用者手動輸入\n",
        "\n"
      ],
      "metadata": {
        "id": "lwgnLGPSuGP1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McKdDJ4B9a_U"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  from google.colab import userdata\n",
        "  os.environ['GROQ_API_KEY'] = userdata.get('Groq') #設定為環境變數供client 使用\n",
        "  hf_token = userdata.get('HuggingFace')\n",
        "\n",
        "  if hf_token:\n",
        "    login(token = hf_token) #登入HuggingFace\n",
        "  else :\n",
        "    raise ValueError(\"No HF Token\")\n",
        "\n",
        "except:\n",
        "  print(\"can not find Colab Secrets. Please enter secret key and token manually.\")\n",
        "  os.environ[\"GROQ_API_KEY\"] = input(\"Please enter Groq API Key (gsk_...): \")\n",
        "  print(\"Please enter Hugging Face Token:\")\n",
        "  login()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**定義Embedding 模型**\n",
        "*   使用Google 的`embeddinggemma-300m`模型將文字轉為向量\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YeEYP2EpuHdV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEaerHgIDj-t"
      },
      "outputs": [],
      "source": [
        "class EmbeddingGemmaEmbeddings(HuggingFaceEmbeddings):\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__(\n",
        "      model_name=\"google/embeddinggemma-300m\",\n",
        "      encode_kwargs={\"normalize_embeddings\": True},\n",
        "      **kwargs\n",
        "    )\n",
        "\n",
        "  def embed_documents(self, texts):\n",
        "    # 針對文檔嵌入加上前綴\n",
        "    texts = [f'title: none | text: {t}' for t in texts]\n",
        "    return super().embed_documents(texts)\n",
        "\n",
        "  def embed_query(self, text):\n",
        "    # 官方檢索建議前綴\n",
        "    return super().embed_query(f'task: search result | query: {text}')\n",
        "\n",
        "embedding_model = EmbeddingGemmaEmbeddings()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Gqs-lspEbVd"
      },
      "source": [
        "###**讀入資料集 : 讀入RAG向量資料庫(FAISS)**\n",
        "1.  從Google Drive 解壓縮夢境解析資料庫\n",
        "2.  使用FAISS 套件載入解壓後的向量索引\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqhp7KF_EaYI"
      },
      "outputs": [],
      "source": [
        "DRIVE_ZIP_PATH = \"/content/drive/MyDrive/Dream/dream_db.zip\"\n",
        "EXTRACT_PATH = \"loaded_db\" # 暫存資料夾\n",
        "\n",
        "if os.path.exists(DRIVE_ZIP_PATH):\n",
        "  if os.path.exists(EXTRACT_PATH):\n",
        "    shutil.rmtree(EXTRACT_PATH) # 清除舊資料，確保載入的是最新版\n",
        "\n",
        "  print(f\"正在解壓縮... ,Source :{DRIVE_ZIP_PATH}\")\n",
        "  shutil.unpack_archive(DRIVE_ZIP_PATH, EXTRACT_PATH)\n",
        "\n",
        "  print(\"Loading FAISS vectorDB...\")\n",
        "  try:\n",
        "    db_path = EXTRACT_PATH\n",
        "\n",
        "    if \"faiss_db\" in os.listdir(EXTRACT_PATH):\n",
        "      db_path = os.path.join(EXTRACT_PATH, \"faiss_db\")\n",
        "\n",
        "    vectorstore = FAISS.load_local(\n",
        "      folder_path=db_path,\n",
        "      embeddings=embedding_model,\n",
        "      allow_dangerous_deserialization=True\n",
        "    )\n",
        "\n",
        "    # 建立檢索器 (Retriever)\n",
        "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})  # k=1 代表只找最相關的那一筆資料\n",
        "    print(\"資料庫載入成功\")\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"資料庫載入失敗: {e}\")\n",
        "    print(f\"目前解壓路徑內容: {os.listdir(EXTRACT_PATH)}\")\n",
        "\n",
        "else:\n",
        "  print(f\"error：can not find file {DRIVE_ZIP_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bQ4pwBYF5jn"
      },
      "source": [
        "###**定義System Prompt**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oIMQU-qF5KM"
      },
      "outputs": [],
      "source": [
        "DREAM_SYSTEM_TEMPLATE = \"\"\"\n",
        "  你是一位精通榮格心理學與超現實主義藝術的「夢境解讀師」。\n",
        "\n",
        "  【參考資料】\n",
        "  {knowledge}\n",
        "\n",
        "  【任務】\n",
        "  請根據使用者的夢境，結合上述參考知識，執行以下三項工作：\n",
        "  1. 深度心理分析:拆解夢境中的關鍵象徵（人物、物品、情境），分析其隱含的潛意識情緒（如焦慮、渴望、恐懼）與現實生活的壓力源。\n",
        "  2. 具體建議:根據分析出的壓力源，提供具體的行動建議（如心理轉念、放鬆練習、生活調整）。\n",
        "  3. 視覺轉譯:將這個夢境的情緒與畫面，轉化為詳細的英文繪圖指令。\n",
        "\n",
        "  【輸出格式規則】\n",
        "  請務必直接輸出標準JSON格式，不要包含任何Markdown標記 (如 ```json)，包含以下三個欄位：\n",
        "\n",
        "  1. \"analysis\": (字串) 深度心理分析。請指出夢中各個意象並解釋其意義，並推測這反映了使用者最近遇到什麼狀況(語氣溫暖專業，長度約100-200字)。\n",
        "  2. \"advice\": (字串) 給使用者的具體建議。例如：「既然夢境顯示您最近壓力很大，建議您嘗試腹式呼吸法...」或「建議給自己安排一場無目的的散步」(長度約100-150字)。\n",
        "  3. \"prompt\": (字串) 給AI繪圖模型的英文指令。\n",
        "    i.繪圖指令必須包含風格詞：Surrealism (超現實主義), cinematic lighting (電影光效), 8k, highly detailed, dreamlike atmosphere.\n",
        "    ii.描述必須具體，例如 \"A giant tooth falling from the sky, cracking the ground...\"\n",
        "  【互動規則】\n",
        "  1. 若使用者的描述太簡略，請不要分析，請用「自然中文」追問細節（例如：當下的情緒？顏色？）。\n",
        "  2. 若資訊已充足(已經收集到夢境的「視覺畫面 (顏色/光影)」、「情緒氛圍」與「關鍵情節」，且經過了至少 1~2 輪的對話)，或使用者明確表示「請分析」、「就這樣」、「沒有其他細節」或「不知道」時，請立刻結束對話。請「只輸出」標準 JSON 格式（包含 analysis, advice, prompt）。\n",
        "  3. 為了避免使用者疲乏，請不要追問超過「3個」問題，且問題盡量簡單好理解。\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **AI Agent 核心邏輯：結合 RAG 知識檢索與對話記憶**\n",
        "賦予AI夢境意象所代表的意涵相關知識 (RAG) 與短期對話記憶 (Context)\n",
        "1. 感知 ：接收使用者最新的夢境描述。\n",
        "2. 檢索 ：使用retriever 從向量資料庫中尋找相關的心理學理論 (RAG)。\n",
        "3. 記憶 ：將Gradio 傳入的歷史對話(history) 轉換為LLM 讀得懂的格式，維持對話連貫性。\n",
        "4. 生成 ：將「系統指令 + 參考知識 + 對話紀錄」打包，發送給Groq產生回應。\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QHFlIyvNuJ-3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cb7BAOsb_2Eu"
      },
      "outputs": [],
      "source": [
        "client = Groq() # 初始化Groq 客戶端\n",
        "\n",
        "def dream_interpreter_agent(user_message, history):\n",
        "  # Retrieval\n",
        "  print(f\"正在檢索關於 '{user_message}' 的心理學知識...\")\n",
        "  try:\n",
        "    docs = retriever.invoke(user_message) # 使用前面載入的retriever 來找資料\n",
        "    knowledge = docs[0].page_content if docs else \"無相關心理學資料\"\n",
        "\n",
        "  except Exception as e:\n",
        "    knowledge = \"資料庫檢索失敗\"\n",
        "    print(f\"Debug: {e}\")\n",
        "\n",
        "  system_instruction = DREAM_SYSTEM_TEMPLATE.format(knowledge=knowledge)\n",
        "\n",
        "  messages = [{\"role\" : \"system\", \"content\" : system_instruction }]\n",
        "\n",
        "  # 將Gradio 的history ([[user, ai], [user, ai]...]) 轉換成API 格式\n",
        "  for user_msg, ai_msg in history:\n",
        "    if user_msg:\n",
        "      messages.append({\"role\": \"user\", \"content\": user_msg})\n",
        "    if ai_msg:\n",
        "      messages.append({\"role\": \"assistant\", \"content\": ai_msg})\n",
        "\n",
        "  messages.append({\"role\": \"user\", \"content\": user_message}) # 加入當前這句話\n",
        "\n",
        "  #call LLM\n",
        "  completion = client.chat.completions.create(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    messages=messages,\n",
        "    temperature=0.7 # 創意度\n",
        "  )\n",
        "\n",
        "  return completion.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**圖象生成**\n",
        "**兩種模式可替換**\n",
        "*  **雲端伺服器運算** : 調用Huggiging Face Inference API，使用 `stable-diffusion-xl-base-1.0` 模型(Colab GPU 資源耗盡時的替代方案)\n",
        "*  **使用Colab GPU運算** : 透過Diffusers在本地部署SDXL-Turbo 模型\n",
        "\n"
      ],
      "metadata": {
        "id": "MA12E6IFuK-T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKfdy0exuOZy"
      },
      "outputs": [],
      "source": [
        "generation_mode = None  # 用來記錄目前是\"local\"還是 \"api\"\n",
        "pipe = None\n",
        "client_img = None\n",
        "if torch.cuda.is_available() :\n",
        "  print(\"偵測到GPU，正在嘗試載入模型(SDXL-Turbo)\")\n",
        "\n",
        "  try :\n",
        "    pipe = AutoPipelineForText2Image.from_pretrained(\n",
        "      \"stabilityai/sdxl-turbo\",\n",
        "      torch_dtype=torch.float16,\n",
        "      variant=\"fp16\"\n",
        "    )\n",
        "\n",
        "    pipe.to(\"cuda\")\n",
        "    print(\"模型載入成功, 目前使用GPU繪圖\")\n",
        "    generation_mode = \"local\"\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"模型載入失敗: {e}\")\n",
        "    print(\"正在嘗試使用Hugging Face Inference API 繪圖...\")\n",
        "\n",
        "else :\n",
        "  print(\"偵測到CPU，正在嘗試使用Hugging Face Inference API 繪圖...\")\n",
        "\n",
        "# 如果本地載入失敗，或是沒有GPU，就執行替代方案 : Hugging Face API雲端繪圖\n",
        "if generation_mode is None :\n",
        "  print(\"正在啟用Hugging Face Inference API 繪圖\")\n",
        "\n",
        "  try:\n",
        "    # 透過Hugging Face Inference API 進行伺服器端運算，跑SDXL 1.0模型\n",
        "    client_img = InferenceClient(model=\"stabilityai/stable-diffusion-xl-base-1.0\", token=hf_token)\n",
        "    print(\"已啟用：Hugging Face 雲端繪圖模式\")\n",
        "  except Exception as e:\n",
        "    print(f\"API 初始化失敗: {e}\")\n",
        "    print(\"錯誤：無法建立任何繪圖服務，請檢查Token或GPU 狀態。\")\n",
        "\n",
        "# 繪圖函式，根據情況自動切換\n",
        "def generate_image(prompt_text) :\n",
        "  if not prompt_text:\n",
        "    print(\"提示詞為空\")\n",
        "    return None\n",
        "\n",
        "  #使用本地GPU繪圖\n",
        "  if generation_mode == \"local\":\n",
        "    try:\n",
        "      print(f\"Local GPU 開始繪圖: {prompt_text[:50]}...\")\n",
        "       # SDXL Turbo 只需要1 step,guidance_scale 設0.0\n",
        "      return pipe(prompt=prompt_text, num_inference_steps=1, guidance_scale=0.0).images[0]\n",
        "    except Exception as e:\n",
        "      print(f\"繪圖失敗: {e}\")\n",
        "      return None\n",
        "\n",
        "    # 使用Hugging Face API\n",
        "  elif generation_mode == \"api\":\n",
        "    try:\n",
        "      print(f\"Cloud API 開始繪圖: {prompt_text[:30]}...\")\n",
        "      return client_img.text_to_image(prompt_text)\n",
        "    except Exception as e:\n",
        "      print(f\"API 繪圖失敗: {e}\")\n",
        "      return None\n",
        "  else:\n",
        "    print(\"統錯誤：沒有可用的繪圖模型。\")\n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnX-sG4nNms_"
      },
      "source": [
        "###Gradio 介面邏輯"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFmfG5XjHMLJ"
      },
      "outputs": [],
      "source": [
        "def chat_process(message, history):\n",
        "  \"\"\"\n",
        "  message: 當前使用者輸入的字串\n",
        "  history: 過去的對話紀錄List (Gradio 傳入)\n",
        "  \"\"\"\n",
        "  ai_response = dream_interpreter_agent(message, history) # Call AI\n",
        "\n",
        "  result_json = None\n",
        "  # 判斷回覆是AI「追問」的問題還是「最終分析」\n",
        "  try:\n",
        "\n",
        "    # 找第一個中括號和最後一個中括號\n",
        "    start_idx = ai_response.find('{')\n",
        "    end_idx = ai_response.rfind('}')\n",
        "\n",
        "    # 只有當同時找到兩個中括號時才嘗試解析\n",
        "    if start_idx != -1 and end_idx != -1:\n",
        "      # 擷取純 JSON 字串\n",
        "      json_str = ai_response[start_idx : end_idx + 1]\n",
        "      result_json = json.loads(json_str)\n",
        "\n",
        "    # 若成功解析JSON 則代表分析完成\n",
        "    if \"analysis\" in result_json:\n",
        "      analysis = result_json.get(\"analysis\", \"無內容\")\n",
        "      advice = result_json.get(\"advice\", \"無內容\")\n",
        "      prompt = result_json.get(\"prompt\", \"\")\n",
        "\n",
        "      report = f\"【深度心理分析】\\n{analysis}\\n\\n【建議】\\n{advice}\" # 將「分析」跟「建議」組合成完整的分析報告\n",
        "      chat_reply = \"為您分析中...\"\n",
        "\n",
        "      return chat_reply, report, prompt, prompt # (聊天室回應, 分析報告, 繪圖指令, 觸發圖片生成)\n",
        "\n",
        "  except (json.JSONDecodeError, TypeError):\n",
        "    # 解析失敗，代表AI還在跟使用者對話\n",
        "    pass\n",
        "\n",
        "  # 若不是 JSON，直接把 AI 的回話丟回聊天室\n",
        "  # 右側欄位回傳 gr.update() 代表「畫面不動」\n",
        "  return ai_response, gr.update(), gr.update(), None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sfIC_MIPCik"
      },
      "source": [
        "###Gradio 介面設計"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Adi75Ee9PCJ0"
      },
      "outputs": [],
      "source": [
        "# 自定義 CSS：標題漸層與置中\n",
        "custom_css = \"\"\"\n",
        ".dream-title {\n",
        "    text-align: center;\n",
        "    background: -webkit-linear-gradient(45deg, #6a11cb 0%, #2575fc 100%);\n",
        "    -webkit-background-clip: text;\n",
        "    -webkit-text-fill-color: transparent;\n",
        "    font-weight: bold;\n",
        "    font-size: 3em;\n",
        "    margin-bottom: 0.5em;\n",
        "}\n",
        ".dream-subtitle {\n",
        "    text-align: center;\n",
        "    font-size: 1.2em;\n",
        "    color: #666;\n",
        "    margin-bottom: 2em;\n",
        "}\n",
        "\"\"\"\n",
        "with gr.Blocks(title=\"互動式夢境諮商室\", theme=gr.themes.Soft(), css=custom_css) as demo:\n",
        "  with gr.Column():\n",
        "    gr.HTML(\"\"\"\n",
        "      <h1 class=\"dream-title\">互動式夢境諮商室</h1>\n",
        "      <p class=\"dream-subtitle\">結合 RAG 知識庫與生成式 AI，解讀你的夢境並繪製潛意識畫面。</p>\n",
        "    \"\"\")\n",
        "\n",
        "  with gr.Row(equal_height=False):\n",
        "    with gr.Column(scale=4):\n",
        "      chatbot = gr.Chatbot(label=\"諮商紀錄\", height=500, type=\"tuples\")\n",
        "      msg = gr.Textbox(label=\"請輸入您的夢境\", placeholder=\"我夢到了... (按 Enter 發送)\")\n",
        "      clear = gr.Button(\"重新開始\")\n",
        "\n",
        "    with gr.Column(scale=3):\n",
        "      gr.Markdown(\"### 分析結果\")\n",
        "      analysis_output = gr.Textbox(label=\"心理分析與建議\", lines=12, interactive=False)\n",
        "\n",
        "      gr.Markdown(\"### 夢境具象\")\n",
        "      image_output = gr.Image(label=\"AI 生成夢境圖像\")\n",
        "      prompt_output = gr.Accordion(\"查看繪圖指令 (Prompt)\", open=False)\n",
        "      with prompt_output:\n",
        "        prompt_text = gr.Textbox(show_label=False)\n",
        "\n",
        "  def respond(message, chat_history):\n",
        "    bot_message, report, prompt, img_trigger = chat_process(message, chat_history)\n",
        "\n",
        "    chat_history.append((message, bot_message)) # 更新歷史紀錄\n",
        "\n",
        "    # 處理圖片生成\n",
        "    gen_img = None\n",
        "    if img_trigger:\n",
        "      gen_img = generate_image(img_trigger)\n",
        "\n",
        "    return \"\", chat_history, report, gen_img, prompt\n",
        "\n",
        "  msg.submit(\n",
        "    fn=respond,\n",
        "    inputs=[msg, chatbot],\n",
        "    outputs=[msg, chatbot, analysis_output, image_output, prompt_text]\n",
        "  )\n",
        "\n",
        "  #清除\n",
        "  clear.click(lambda: (None, [], None, None, None), outputs=[msg, chatbot, analysis_output, image_output, prompt_text])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  demo.launch(\n",
        "    share=True,\n",
        "    debug=True\n",
        "  )\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOTQ+1veTYkAcdlTxQh8BOd",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}